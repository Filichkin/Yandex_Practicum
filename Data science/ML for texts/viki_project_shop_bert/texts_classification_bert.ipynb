{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99226ecb",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Проект для «Викишоп» с использованием BERT<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-описание-данных\" data-toc-modified-id=\"Загрузка-и-описание-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузка и описание данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод-по-загрузке-данных\" data-toc-modified-id=\"Вывод-по-загрузке-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Вывод по загрузке данных</a></span></li></ul></li><li><span><a href=\"#Эмбеддинги-BERT\" data-toc-modified-id=\"Эмбеддинги-BERT-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Эмбеддинги BERT</a></span></li><li><span><a href=\"#Подготовка-данных-и-обучение-моделей\" data-toc-modified-id=\"Подготовка-данных-и-обучение-моделей-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Подготовка данных и обучение моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Предсказание-лучшей-модели\" data-toc-modified-id=\"Предсказание-лучшей-модели-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Предсказание лучшей модели</a></span></li></ul></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Общий вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7fa779",
   "metadata": {},
   "source": [
    "# Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b08d9ab",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "Постройте модель со значением метрики качества F1 не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1673afb",
   "metadata": {},
   "source": [
    "# Инструкция для проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7587f132",
   "metadata": {},
   "source": [
    "Решить задачу можно как с помощью BERT, так и без этой нейронки. Если хотите попробовать BERT —\n",
    "Выполните проект локально. В тренажере тетрадь Jupyter ограничена 4 ГБ оперативной памяти — для проекта с BERT этого может не хватить.\n",
    "\n",
    "Упомяните BERT в заголовке проекта в первой ячейке:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c591854",
   "metadata": {},
   "source": [
    "Выполнить проект без BERT можно локально или в нашем тренажёре.\n",
    "В любом случае алгоритм решения выглядит так:\n",
    "Загрузите и подготовьте данные.\n",
    "Обучите разные модели.\n",
    "Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4a72b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import nltk\n",
    "import torch\n",
    "import transformers\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from tqdm import notebook\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a087db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608774b4",
   "metadata": {},
   "source": [
    "### Загрузка и описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17827054",
   "metadata": {},
   "source": [
    "Данные находятся в файле `toxic_comments.csv`\n",
    "\n",
    "Текст комментария содержится в столбце **text**\n",
    "\n",
    "Целевой признак - **toxic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a04ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_local = '/Users/alexfil/Desktop/Practicum/Проекты/ml_texts/toxic_comments.csv'\n",
    "file_ya = 'https://code.s3.yandex.net/datasets/toxic_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87e60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(file_local) \n",
    "except:\n",
    "    df = pd.read_csv(file_ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44cbc3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66050487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66266769",
   "metadata": {},
   "source": [
    "Удалим неизвестный столбец:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "397a6930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('Unnamed: 0', axis = 1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c54947dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f525127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff5bd53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b8da28",
   "metadata": {},
   "source": [
    "#### Вывод по загрузке данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831127c0",
   "metadata": {},
   "source": [
    "1. Загружен датасет размерностью 159292 строки и 3 столбца\n",
    "2. Произведено удаление неизвестного столбца 'Unnamed: 0'\n",
    "3. Пропущенных значений и дубликатов не выявленно\n",
    "4. Работать будем с итоговым датасетом размерностью 159292 строки и 2 столбца"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806207d",
   "metadata": {},
   "source": [
    "### Эмбеддинги BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d998c",
   "metadata": {},
   "source": [
    "Чтобы не создавать эмбеддинги слишком долго, из выборки используется только 500 случайных элементов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b144dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=500, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2fca8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    444\n",
       "1     56\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581bd35b",
   "metadata": {},
   "source": [
    "Инициализируем токенизатор как объект класса BertTokenizer(). Передадим ему аргумент vocab_file — это файл со словарём, на котором обучалась модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ec41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = '/Users/alexfil/Desktop/Practicum/Теория/ML texts/Bert/sentence_ru_cased_L-12_H-768_A-12_pt_v1/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "debf2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer(vocab_file=vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ad6a9",
   "metadata": {},
   "source": [
    "Преобразуем текст в номера токенов из словаря методом encode() с добавлением токенов начала и конца текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "908dbea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42634d2",
   "metadata": {},
   "source": [
    "Определение максимальной длины токена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25a23c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина токена: 1542\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "print('Максимальная длина токена:', max_len) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd5e53",
   "metadata": {},
   "source": [
    "Применим метод padding (англ. «отступ»), чтобы после токенизации длины исходных текстов в корпусе были равными. Только при таком условии будет работать модель BERT. \n",
    "Также уменьшим размер токенов до 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ebe966",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "padded = padded[:, :512] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfcccc",
   "metadata": {},
   "source": [
    "Теперь поясним модели, что нули не несут значимой информации. Это нужно для компоненты модели, которая называется «внимание» (англ. attention). Отбросим эти токены и «создадим маску» для действительно важных токенов, то есть укажем нулевые и не нулевые значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6645d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c6960",
   "metadata": {},
   "source": [
    "Инициализируем саму модель класса BertModel. Передадим ей файл с предобученной моделью и конфигурацией: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db38de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.BertConfig.from_json_file(\n",
    "    '/Users/alexfil/Desktop/Practicum/Теория/ML texts/Bert/sentence_ru_cased_L-12_H-768_A-12_pt_v1/config.json'\n",
    ")\n",
    "model = transformers.BertModel.from_pretrained(\n",
    "    '/Users/alexfil/Desktop/Practicum/Теория/ML texts/Bert/sentence_ru_cased_L-12_H-768_A-12_pt_v1/pytorch_model.bin',\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63107e6b",
   "metadata": {},
   "source": [
    "Преобразование текстов в эмбеддинги:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3774112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc292e5d0494157a55e5e58b893845e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(\n",
    "            padded[batch_size * i:batch_size *(i + 1)]\n",
    "        ) \n",
    "        attention_mask_batch = torch.LongTensor(\n",
    "            attention_mask[batch_size * i:batch_size * (i + 1)]\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(\n",
    "                batch, attention_mask=attention_mask_batch\n",
    "            )\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c23668a",
   "metadata": {},
   "source": [
    "Соберём все эмбеддинги в матрицу признаков вызовом функции concatenate():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f598ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate(embeddings)\n",
    "y = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4178955c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 768)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6db28219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720d5010",
   "metadata": {},
   "source": [
    "###  Подготовка данных и обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfe0a1c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.4, \n",
    "    stratify=y, \n",
    "    random_state=RANDOM_STATE\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19d2c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_randomsearch(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    model, \n",
    "    params, \n",
    "    data_random, \n",
    "    data_times \n",
    "):\n",
    "    \n",
    "    start_time = time.time() \n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('sampl', SMOTE(random_state=RANDOM_STATE)), \n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        params,\n",
    "        scoring='f1',\n",
    "        cv=5,\n",
    "        n_iter=5\n",
    ")\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    finish_time = time.time()\n",
    "    funtion_time = finish_time - start_time\n",
    "    \n",
    "    data_random.append(random_search)\n",
    "    data_times.append(funtion_time) \n",
    "    \n",
    "    return data_random, data_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b1d0311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_result(randoms, data_times, model_name):\n",
    "    print('Модель    :', model_name)\n",
    "    print('Метрика F1:', randoms[-1].best_score_)\n",
    "    print(f'Время     : {data_times[-1]} секунд')\n",
    "    print('Параметры :', randoms[-1].best_estimator_[-1].get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9f2bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random = []\n",
    "data_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79e30122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель    : LogisticRegression\n",
      "Метрика F1: 0.33166666666666667\n",
      "Время     : 1.7133798599243164 секунд\n",
      "Параметры : {'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l1', 'random_state': 42, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "params = [{\n",
    "    'clf__solver': ('liblinear', 'lbfgs'),\n",
    "    'clf__penalty': ('l1', 'l2'),\n",
    "    'clf__C': list(range(5, 15, 1))\n",
    "}]\n",
    "data_random, data_times = model_pipeline_randomsearch(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    LogisticRegression(\n",
    "        random_state=RANDOM_STATE\n",
    "    ), \n",
    "    params, \n",
    "    data_random, \n",
    "    data_times \n",
    ")\n",
    "print_model_result(data_random, data_times, 'LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31aead19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель    : CatBoostClassifier\n",
      "Метрика F1: 0.33026228673287494\n",
      "Время     : 62.22422766685486 секунд\n",
      "Параметры : {'iterations': 50, 'learning_rate': 1, 'depth': 4, 'verbose': False, 'random_state': 42, 'early_stopping_rounds': 10}\n"
     ]
    }
   ],
   "source": [
    "params = [{\n",
    "    'clf__learning_rate': (0.05, 1), \n",
    "    'clf__depth': (4, 6),\n",
    "}]\n",
    "data_random, data_times = model_pipeline_randomsearch(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    CatBoostClassifier(iterations=50,\n",
    "                       early_stopping_rounds=10,\n",
    "                       random_state=RANDOM_STATE,\n",
    "                       verbose=False\n",
    "                      ), \n",
    "    params, \n",
    "    data_random, \n",
    "    data_times \n",
    ")\n",
    "print_model_result(data_random, data_times, 'CatBoostClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a8e7d4",
   "metadata": {},
   "source": [
    "Выбор лучшей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "411a4850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее время           : 1.7133798599243164\n",
      "Лучший показатель F1   : 0.33166666666666667\n",
      "Лучшая модель          :\n",
      "RandomizedSearchCV(cv=5,\n",
      "                   estimator=Pipeline(steps=[('sampl', SMOTE(random_state=42)),\n",
      "                                             ('clf',\n",
      "                                              LogisticRegression(random_state=42))]),\n",
      "                   n_iter=5,\n",
      "                   param_distributions=[{'clf__C': [5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                                    13, 14],\n",
      "                                         'clf__penalty': ('l1', 'l2'),\n",
      "                                         'clf__solver': ('liblinear',\n",
      "                                                         'lbfgs')}],\n",
      "                   scoring='f1')\n",
      "Лучшие параметры модели:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__memory': None,\n",
       " 'estimator__steps': [('sampl', SMOTE(random_state=42)),\n",
       "  ('clf', LogisticRegression(random_state=42))],\n",
       " 'estimator__verbose': False,\n",
       " 'estimator__sampl': SMOTE(random_state=42),\n",
       " 'estimator__clf': LogisticRegression(random_state=42),\n",
       " 'estimator__sampl__k_neighbors': 5,\n",
       " 'estimator__sampl__n_jobs': None,\n",
       " 'estimator__sampl__random_state': 42,\n",
       " 'estimator__sampl__sampling_strategy': 'auto',\n",
       " 'estimator__clf__C': 1.0,\n",
       " 'estimator__clf__class_weight': None,\n",
       " 'estimator__clf__dual': False,\n",
       " 'estimator__clf__fit_intercept': True,\n",
       " 'estimator__clf__intercept_scaling': 1,\n",
       " 'estimator__clf__l1_ratio': None,\n",
       " 'estimator__clf__max_iter': 100,\n",
       " 'estimator__clf__multi_class': 'auto',\n",
       " 'estimator__clf__n_jobs': None,\n",
       " 'estimator__clf__penalty': 'l2',\n",
       " 'estimator__clf__random_state': 42,\n",
       " 'estimator__clf__solver': 'lbfgs',\n",
       " 'estimator__clf__tol': 0.0001,\n",
       " 'estimator__clf__verbose': 0,\n",
       " 'estimator__clf__warm_start': False,\n",
       " 'estimator': Pipeline(steps=[('sampl', SMOTE(random_state=42)),\n",
       "                 ('clf', LogisticRegression(random_state=42))]),\n",
       " 'n_iter': 5,\n",
       " 'n_jobs': None,\n",
       " 'param_distributions': [{'clf__solver': ('liblinear', 'lbfgs'),\n",
       "   'clf__penalty': ('l1', 'l2'),\n",
       "   'clf__C': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}],\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'random_state': None,\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': 'f1',\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_random_best = data_random[0]\n",
    "data_times_best = data_times[0]\n",
    "\n",
    "for i in range(0, len(data_random)):\n",
    "    if data_random[i].best_score_ > data_random_best.best_score_: \n",
    "        data_random_best = data_grids[i]\n",
    "        data_times_best = data_times[i]\n",
    "\n",
    "print('Лучшее время           :', data_times_best)\n",
    "print('Лучший показатель F1   :', data_random_best.best_score_)\n",
    "print('Лучшая модель          :') \n",
    "print(data_random_best) \n",
    "print('Лучшие параметры модели:') \n",
    "data_random_best.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d70ddc",
   "metadata": {},
   "source": [
    "В данный момент мы использовали только 500 случайных объектов из 159292 имеющихся в датафрейме. \n",
    "Такого количества объектов не достаточно для полноценного обучения модели предсказания классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5285540",
   "metadata": {},
   "source": [
    "#### Предсказание лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b112f572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Показатель F1     : 0.45454545454545453\n",
      "Время предсказания: 0.0016160011291503906 секунд\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict = data_random_best.predict(X_test)\n",
    "finish_time = time.time()\n",
    "funtion_time = finish_time - start_time\n",
    "print('Показатель F1     :', f1_score(y_test, predict))\n",
    "print(f'Время предсказания: {funtion_time} секунд')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9567f7",
   "metadata": {},
   "source": [
    "Метрика лучшей модели на тестовой выборке равна 0.33, что не соответствует условиям задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56377320",
   "metadata": {},
   "source": [
    "###  Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f47498",
   "metadata": {},
   "source": [
    "1. Заказчиком предоставлен датасет размерностью 159292 строки и 3 столбца\n",
    "\n",
    "2. Произведено удаление неизвестного столбца 'Unnamed: 0'\n",
    "\n",
    "3. Пропущенных значений и дубликатов не выявленно\n",
    "\n",
    "4. Работа выполнена с итоговым датасетом размерностью 159292 строки и 2 столбца\n",
    "\n",
    "5. Чтобы не создавать эмбеддинги слишком долго, из выборки используется только 500 случайных элементов\n",
    "\n",
    "5. Текст преобразован в эмбеддинги с помощью BERT\n",
    "\n",
    "6. Выполнена разбивка на тренировочную выборки с разметностью test_size=0.4\n",
    "\n",
    "7. Выполнено обучение двух моделей LogisticRegression и CatBoostClassifier\n",
    "\n",
    "10. Лучшей моделью на тренировочной выборке является LogisticRegression. Метрика F1 равна 0.33, что в условиях использования только 500 случайных элементов выборки не соответствет условию задачи.\n",
    "\n",
    "11. Метрика лучшей модели на тестовой выборке равна 0.45, что также не соответствует условиям задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b87928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Проект для «Викишоп» с использованием BERT",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
